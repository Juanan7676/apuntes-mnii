\renewcommand{\tt}{t}
\newcommand{\yy}{y}
\newcommand{\yn}{{\yy_n}}
\newcommand{\ynn}{{\yy_{n+1}}}
\newcommand{\ta}{a}
\newcommand{\tb}{b}
\newcommand{\tn}{{\tt_n}}
\newcommand{\tnn}{{\tt_{n+1}}}
\newcommand{\ycero}{{y_a}}
\newcommand{\sol}{y}
\newcommand{\lipschitz}{Lipschitz\xspace}
\newcommand{\globLipschitz}{$y$--\lipschitz}
\newcommand{\locLipschitz}{localmente $y$--\lipschitz}

\chapter[Problemas de valor inicial para EDOs de primer orden]
{Problemas de valor inicial para ecuaciones diferenciales de primer
  orden%
  \footnote{\licenseInfo}}

Son muy numerosos los problemas (con orígenes diversos como la física,
química, biología o economía) que se formulan matemáticamente en
términos de ecuaciones diferenciales, es decir, ecuaciones cuya
incógnita, una función $y(x)$, describe un fenómeno dado a través de
una ley que relaciona a esta función con sus derivadas. La formulación
adecuada de esta ley junto a algunos datos adicionales (condiciones
iniciales) garantizarán el buen planteamiento del problema.

Este tema se centra en la resolución numérica de problemas de valor
inicial (o problemas de Cauchy) asociados a ecuaciones diferenciales
ordinarias (EDO). Este tipo de problemas se escriben de la siguiente
forma:
\begin{equation}
  \label{eq:pvi}
  \tag{PVI}
  \left\{
  \begin{aligned}
    &y' = f(\tt,\yy), \quad \tt\in[\ta,\tb],
    \\
    &y(\ta) = \ycero,
  \end{aligned}
  \right.
\end{equation}
donde la función (continua) $f:[\ta,\tb]\times\Rset\to\Rset$ y el
estado inicial $\ycero\in\Rset$ son datos conocidos. En el próximo
tema se estudia el caso general, donde
$f:[\ta,\tb]\times\Rset^n\to\Rset^n$ e $\ycero\in\Rset^n$, con
$n\in\Nset$. En numerosos problemas de la ciencia y la ingeniería, la
variable $\tt$ representa el tiempo aunque no siempre es necesario que
sea así. Con frecuencia hablaremos de $\tt$ como la <<variable
temporal>>).

\begin{definition}
  Llamamos solución de~\eqref{eq:pvi} a toda función $\sol\in
  C^1([\ta,\tb])$ tal que $\sol'(\tt)=f(\tt,\sol(\tt))$ para todo
  $\tt\in[\ta,\tb]$ y además $\sol(\ta)=\ycero$.\label{def:3}
\end{definition}

Obsérvese que, según esta definición, el
concepto de solución tiene un sentido global (en todo el intervalo
$[a,b]$), no local (en un entorno de $\ta$).
Como paso previo a la resolución numérica de~\eqref{eq:pvi}, deberemos
garantizar que el problema~\eqref{eq:pvi} está bien planteado, es
decir asegurar la existencia y unicidad de solución en el sentido
anterior. 

\section{Resultados teóricos preliminares}
\label{sec:tema4:resultados-teoricos}

Antes de comenzar a estudiar métodos numéricos para la resolución de
problemas de valor inicial, recordaremos en esta sección algunos
resultados teóricos relacionados con la existencia y unicidad de
solución del problema de Cauchy~(\ref{eq:pvi}), que han sido adaptados
a las necesidades de las siguientes secciones y serán dados sin
demostración. La clave en estos resultados será el analizar si la
función $f(x,y)$ es verifica la condición de Lipschitz que se define a
continuación:

\begin{definition}
  \label{def:lipschitz}
  Decimos que una función $f(\tt,y)$ verifica la condición de
  \resaltar{Lipschitz uniformemente} (o globalmente) respecto a $y$ en
    $[\ta,\tb]$ (o simplemente que $f$ es \globLipschitz)
    si existe $L>0$ tal que
  \begin{equation*}
    |f(\tt,y) - f(\tt,z)| \le L |y-z|, \quad \forall \tt\in [\ta,\tb],
    \quad  \forall y,z\in \Rset.
  \end{equation*}
  Decimos que una función $f(\tt,y)$ verifica la condición de
  \resaltar{Lipschitz localmente} respecto a $y$ en
  $[\ta,\tb]$ (o que $f$ es \locLipschitz) si para todo compacto
  $K\subset\Rset$ existe $L_K>0$ tal que
  \begin{equation*}
    |f(\tt,y) - f(\tt,z)| \le L_K |y-z|, \quad \forall \tt\in [\ta,\tb],
    \quad  \forall y,z\in K.
  \end{equation*}
\end{definition}

Antes del siguiente comentario, fijaremos la siguiente
\textbf{notación}: $\dy f$ designará a la derivada parcial de $f$
respecto a $y$, es decir $\dy f(\tt,y) = \frac{\partial f}{\partial
  \yy}(\tt,y)$. Para el resto de las variables se usarán notaciones
similares.
\begin{remark}
  En la práctica, para estudiar si una función es (local o
  globalmente) Lipschitz se suelen usar las siguientes condiciones
  suficientes:
  \begin{enumerate}
  \item Si $\dy f$ es continua en $[\ta,\tb]\times\Rset$, entonces $f$
    es \locLipschitz.
  \item Si además $\dy f$ está acotada en
    $[\ta,\tb]\times\Rset$, entonces $f$ es uniformemente
    \globLipschitz.
  \end{enumerate}
  Comprobaremos la segunda de estas afirmaciones (la primera se
  demuestra de forma análoga, usando que $\dy f$ está acotada
  en todo compacto $K\subset\Rset)$.
  Si $\dy f$ es continua en $[\ta,\tb]\times\Rset$, entonces en cada
  <<instante>> $t\in[\ta,\tb]$ la función
  $$\dy f(t,\cdot):\Rset \to \Rset$$
  es continua. Aplicando el teorema del valor medio, se tiene que
  dados $y$, $z\in\Rset$ existe $y^*$ entre $y$ y $z$ tal que
  \begin{equation*}
    |f(\tt,y)-f(\tt,z)| = |\dy f(\tt,y^*) \cdot (y-z)|.
  \end{equation*}
  Como además  $\dy f$ está acotada, existe $L>0$ tal que $|\dy
  f(\tt,y)|\le L$ para todo $(\tt,y)\in [\ta,\tb]\times\Rset$ y
  entonces 
  \begin{equation*}
    |f(\tt,y) - f(\tt,z)| \le L |y-z|.
  \end{equation*}
\end{remark}

\begin{example}
  La función $$f(x,y)=y^2$$ es \locLipschitz en cualquier intervalo
  $[\ta,\tb]$, pues su derivada parcial $\dy f(x,y)=2y$ es continua. Sin
  embargo, esta función no está acotada cuando $y\in\Rset$, por lo que
  no tenemos garantías de que $f(x,y)$ sea uniformemente \globLipschitz.
  
  Veamos que realmente $f(x,y)$ no es a uniformemente \globLipschitz,
  comprobando que para cualquier constate $L>0$, podemos encontrar dos
  valores, $y_L$, $z_L\in\Rset$ de forma que
  \begin{equation*}
  |f(\tt,y_L)-f(\tt,z_L)| >  L  |y_L-z_L|.
 \end{equation*}
 Por ejemplo, dada $L>0$ podemos tomar $y_L=L$ y $z_L=0$, así el
 primer miembro es
 \begin{align*}
   |f(\tt,y_L)-f(\tt,z_L)|&=|L+0|\cdot |L-0|=4L^2,
   \intertext{mientras que el segundo miembro resulta} 
   L|y_L-z_L|&=2L^2<4L^2.
 \end{align*}
\end{example}

A continuación, presentamos los resultados teóricos fundamentales. El
primer Teorema utiliza hipótesis más débiles (\locLipschitz), aunque
sin alcanzar directamente la existencia y unicidad de solución en todo
$[a,b]$.  El Teorema~\ref{thm:existencia-unif-lipschitz} garantiza la
existencia y unicidad de solución de~\eqref{eq:pvi} en $[a,b]$,
aunque a costa de imponer una hipótesis muy fuerte (Lipschitz
uniforme), que reduce considerablemente el rango de problemas
diferenciales abarcados.
\begin{theorem}
  \label{thm:existencia-loc-lipschitz}
  Sea $f$ continua en $[\ta,\tb]\times\Rset$ y \locLipschitz. Entonces, para
  cualquier inicialización $\ycero\in\Rset$:
  \begin{enumerate}
  \item Existe una única solución local (definida en
    $[\ta,\ta+\varepsilon]$ para algún $\varepsilon>0$) y existe una
    única solución maximal (es decir, definida en todo $[a,b]$ o bien
    en $[\ta,c)\subset[\ta,\tb]$, para algún $c\in(\ta,\tb)$, y no
    prolongable a $\tt>c$) de~\eqref{eq:pvi}.
  \item Además: o bien la solución maximal $\sol(\tt)$  está definida en todo
    $[\ta,\tb]$, o bien ésta explota en tiempo finito (es decir existe
    $c\in (\ta,\tb)$ tal que $\lim_{\tt\to c^-} \sol(\tt) = \infty$).
  \end{enumerate}
\end{theorem}

\begin{theorem}[Picard]
  \label{thm:existencia-unif-lipschitz}
  Sea $f$ continua en $C^0([\ta,\tb]\times\Rset$ y (globalmente) \globLipschitz.
  Entonces, para cualquier inicialización $\ycero\in\Rset$, existe una
  única solución de~\eqref{eq:pvi}, que está definida en todo el
  intervalo $[\ta,\tb]$.% Además, para todo $\tt\in[\ta,\tb]$
  % se tiene la siguiente desigualdad:
  % \begin{equation*}
  %   |y(\tt)-y(\ta)| \le (\tb-\ta) \Big( \max_{\tt\in[\ta,\tb]}
  %     f(\tt,y(\ta))\Big) e^{L(\tt-\ta)}.
  % \end{equation*}
\end{theorem}

En lo que sigue, estudiaremos el análisis numérico de problemas
diferenciales en los que, en principio, la función $f(\tt,y)$ es tan
solo \locLipschitz. Por lo tanto el estudio de la existencia de
solución en $[\ta,\tb]$ no será una tarea inmediata. Usando el
Teorema~\ref{thm:existencia-loc-lipschitz}, intentaremos demostrar que
la solución maximal del problema~(\ref{eq:pvi}) está acotada en
$[\ta,\tb]$ y por tanto no explota en tiempo finito en este intervalo,
garantizando así existencia y unicidad de solución en $[\ta,\tb]$ (ver
en el ejemplo~\ref{ex:existencia-unicidad-loc-lipschitz}). Con este
propósito, recordamos ahora algunas propiedades interesantes de las
ecuaciones diferenciales que nos resultarán de gran utilidad.

\begin{proposition}[Algunas propiedades de las soluciones de~(\ref{eq:pvi})]
\label{pro:propiedades-pvi}
  Bajo las hipótesis del teorema~\ref{thm:existencia-loc-lipschitz}
  ($f$ \locLipschitz):
  \begin{enumerate}
  \item Sean $\sol_1(\tt)$ y $\sol_2(\tt)$ las soluciones de dos
    problemas del tipo~\eqref{eq:pvi} para la \textbf{misma ecuación
    diferencial} $y'=f(\tt,y)$ pero con \textbf{distintas condiciones
    iniciales}, es decir:
    $$\sol_1(\ta)<\sol_2(\ta)$$ 
    Entonces las gráficas de $\sol_1$ e $\sol_2$ no se cortan en
    ningún punto. En concreto, si $\sol_1$ y $\sol_2$ están
    definidas, respectivamente, en los intervalos $I_1$ e $I_2$,
    entonces
    \begin{equation*}
      \sol_1(\tt) < \sol_2(\tt), \quad \forall \tt \in I_1
      \cap I_2.
    \end{equation*}
    
  \item Sean $\sol_1(\tt)$ y $\sol_2(\tt)$ las soluciones de dos
    problemas del tipo~\eqref{eq:pvi} con la \textbf{misma condición
      inicial} pero con \textbf{ecuaciones diferenciales distintas},
    $y'=f_1(\tt,y)$ $y'=f_2(\tt,y)$. Si
    $$
    f_1(\tt,y) \le f_2(\tt,y) \quad \forall \tt\in[\ta,\tb], \quad
    \forall y\in\Rset,
    $$
    entonces
    $$
    \sol_1(\tt)\le \sol_2(\tt) \quad \forall \tt \in
    I_1 \cap I_2.
    $$
  \end{enumerate}
\end{proposition}

\begin{example}
  \renewcommand{\tt}{x}
  \label{ex:existencia-unicidad-loc-lipschitz}
  Estudiaremos la existencia y unicidad de solución del siguiente
  problema de valor inicial: 
  \begin{equation*}
    \left\{
      \begin{aligned}
        &y' = -y^2+2y\,\cos \tt, \quad \tt\in [0,2],\\
        &y(0)=1.
      \end{aligned}
    \right.
  \end{equation*}
  En primer lugar, $f(x,y)=-y^2+2y\,\cos \tt$ y $\dy f(t,y)=-2y+2\cos
  t$ son continuas en $[0,2]\times\Rset$, luego $f$ es \locLipschitz,
  por lo que (según el teorema~\ref{thm:existencia-loc-lipschitz})
  existe una única solución maximal, a la que denominaremos
  $\sol(\tt)$, definida en $I=[0,2]$ o bien en $I=[0,c)$ con
  $c<2$. Pero esta última posibilidad no se verifica, pues entonces
  $\sol(\tt)$ explotaría en $c$, pero veremos a continuación que
  $\sol(\tt)$ está acotada:
  \begin{enumerate}
  \item Sea $\sol_1$ la solución del problema de valor inicial para la
    misma ecuación diferencial pero para la condición inicial
    $y(0)=0$. Está claro que su única solución es $\sol_1(\tt)=0$
    para todo $\tt\in\Rset$. Y como $0=\sol_1(0)<\sol(0)=1$, entonces
    (según la proposición~\ref{pro:propiedades-pvi}, parte 2) podemos
    asegurar que $\sol$ está acotada inferiormente:
    \begin{equation*}
      0=\sol_1(\tt)<\sol(\tt), \quad \forall \tt\in I.
    \end{equation*}
  \item Sea ahora $f_2(\tt,y)=-y^2+2y$. Como $\cos\tt \le 1$  (y como
    ya podemos suponer $y>0$):
    $$f(\tt,y)=-y^2+2y\cos\tt \le -y^2+2y = f_2(\tt,y)\quad
    \forall \tt\in I, \forall y\in\Rset^+.$$ 
    Ahora podemos calcular
    directamente la solución $\sol_2$ del problema de valor inicial
    $y'=f_2(\tt,y)$, $y(0)=1$ (ya que la ecuación es autónoma),
    obteniendo:
    $$
    \sol_2(\tt)=\frac{2e^{2\tt}}{1+e^{2\tt}},
    $$
    función continua y por tanto acotada superiormente en $[0,2]$.
    Según la proposición~\ref{pro:propiedades-pvi} (parte 1)
    \begin{equation*}
      \sol(\tt)\le\sol_2(\tt)
    \end{equation*}
    y por tanto $\sol(\tt)$ está también acotada superiormente en
    $[0,2]$. Por lo tanto, $\sol$ está definida en todo $[0,2]$.
  \end{enumerate}
  \renewcommand{\tt}{t}
\end{example}

\section{El método de Euler}

A partir de ahora, nuestro objetivo será la descripción, análisis e
implementación de distintos métodos numéricos para la aproximación de
la solución de~\eqref{eq:pvi}. Estos métodos partirán con la
definición de una partición del intervalo $[\ta,\tb]$, formada por
$N+1$ puntos:
\begin{equation*}
  \ta=\tt_0 < \tt_1 < \cdots < \tt_N=\tb.
\end{equation*}
Por simplicidad, supondremos que la partición es uniforme, es decir,
\begin{equation*}
  \text{ si } h=\frac{b-a}{N}, \quad \text{entonces} \quad
  \tt_n=\ta+n\cdot h,\quad \forall n=0\dots,N
\end{equation*}
(en particular, $\tt_0=a$ y $\tt_N=b$). A continuación procedemos como
sigue:
\begin{enumerate}
\item Usamos el dato inicial $y_a$ para arrancar el método numérico,
  definiendo $y_0=y_a$ (más generalmente, $y_0\approx y_a$)
\item Seguidamente definimos una sucesión de forma que $y_{n+1}$ se
  calcula a partir de $y_n$ (y posiblemente de $y_{n-1}$, ...,
  $y_{n-k}$ para algún $k\ge 1$), con el fin de que
  $y_n\approx\sol(\tn)$. 
\end{enumerate}
Nuestro objetivo será que el método sea \textit{convergente}, en el
sentido de que la solución aproximada $\{\yn\}_n$ ``converja a la
solución exacta'' $\{\sol(\tn)\}_n$ cuando $h\to 0$. Íntimamente
relacionados con la convergencia están los conceptos de
``\textit{estabilidad}'' y ``\textit{consistencia}'', que estudiaremos
más adelante.
% \begin{enumerate}
% \item El método es \textit{consistente}, si la solución exacta
%   $\{\sol(\tn)\}_n$ ``verifica aproximadamente'' el esquema
%   numérico
% \item El método es \textit{estable} si ``responde continuamente'' a
%   perturbaciones en los datos iniciales.
% \end{enumerate}
% Más adelante distinguiremos entre métodos de un paso, en los que
% para calcular $y_{n+1}$ utilizamos solamente de $y_n$ y métodos
% multipaso, en los que  $y_{n+1}$ depende de los datos en varias etapas
% anteriores ($y_{n}$, $y_{n-1}$, ..., $y_{n-k}$ para algún $k\ge 1$.)

El método más sencillo es el de Euler (más precisamente, el método
de Euler explícito):
\begin{equation}
\label{eq:metodo-euler}
\left\{
\begin{aligned}
  &y_0 = \ycero, \\
  &y_{n+1} = \yn + h f(\tn, \yn), \quad n=0,\dots,N-1.
\end{aligned}
\right.
\end{equation}

Este método admite varias interpretaciones:

\subsection{Interpretaciones del método de Euler}

\subsubsection*{Interpretación geométrica}
En la ecuación $y(\tt)'=f(\tt,y(\tt))$ se puede interpretar que
$f(\tt,y(\tt))$ marca la pendiente (la derivada) de la solución,
$\sol(\tt)$ en cada instante $\tt\in [\ta,\tb]$.

\begin{center}
  \begin{graficaTikz}[width=23em, height=17em]
    \begin{axis}[ \axisXYmiddle, xtick=\empty, ytick=\empty, legend
      pos = north east, xlabel=$t$ ]
      % Draw a curve
      \addplot[domain=1.3:3.3, blue, ultra thick] {20+x*x*x*x};
      \addplot[domain=1.5:3.1, red, thick] {36+32*(x-2)};
      % Plot a label at curve root
      \node[coordinate, medium dot, 
            pin={[fill=blue!10!white]120:{\scriptsize $\sol(\tn)$}}] at
            (axis cs:2,36) {}; 
      \node[coordinate, medium dot, blue,
            pin={[fill=blue!10!white]120:{\scriptsize $\sol(\tt_{n+1})$}}] at
            (axis cs:2.7,73.144) {}; 
      % \node[coordinate, medium dot, blue, pin=100:{\scriptsize
      %   $\sol(\tt_{n+1})$}] at (axis cs:2.7,73.144) {};
      \addplot[dashed] coordinates {(2,7) (2,36)};
      \addplot[dashed] coordinates {(2.7,7) (2.7,58.4)};
      \node[coordinate, medium dot, pin=-30:{$y_{n}$}] at
      (axis cs:2,36) {}; 
      \node[coordinate, medium dot, pin=-30:{$y_{n+1}$}] at
      (axis cs:2.7,58.4) {}; 
      % Draw the name of curve
      \legend {$y(t)$};
    \end{axis}
  \end{graficaTikz}
\end{center}

Por tanto, suponiendo que $\yn$ es una buena aproximación de
$\sol(\tn)$ (por simplificar, $\yn=\sol(\tn)$):
\begin{enumerate}
\item Calculamos la recta, $r$, que pasa por $(\tn,\yn)$ y tiene pendiente
  $f(\tt_n, \yn)$:
  $$
  r(\tt) = \yn +  f(\tt_n, \yn) (\tt-\tt_n).
  $$
\item Calculamos $y_{n+1}$ como la ordenada de esta recta en
  $\tt=\tt_{n+1}$ es decir:
  $$
  y_{n+1} = r(\tt_{n+1}) = 
  \yn +  f(\tt_n, \yn) (\tt_{n+1}-\tt_n) = \yn +  f(\tt_n, \yn) \cdot h.
  $$
\end{enumerate}
Así obtenemos el método de Euler~\eqref{eq:metodo-euler}.

\subsubsection*{Desarrollo de Taylor}

Suponiendo que $\sol(t)$ (la solución exacta de~(\ref{eq:pvi})) es de
$C^2([\ta,\tb])$, podemos hacer su desarrollo de Taylor en $\tn$:
\begin{equation*}
  \sol(\tnn)=\sol(\tn+h) = \sol(\tn) + h\sol'(\tn) + \frac{h^2}{2} y''(\xi),
\end{equation*}
donde $\xi\in(\tn,\tnn)$. Como $\sol''$ está acotada, el último
término (el resto) será despreciable cuando $h$ es suficientemente
pequeño (pues contiene el factor $h^2$):
\begin{align}
  \label{eq:euler.taylor.1}
  \sol(\tnn)&\approx \sol(\tn) + h\sol'(\tn),
  \intertext{es decir,}
  \notag
  \sol(\tnn)&\approx \sol(\tn) + h f(\tn,y(\tn)),
  \intertext{y aproximando $\sol(\tn)\approx \yn$, $\sol(\tnn)\approx\ynn$:}
  \notag
  \ynn &\approx \yn + h f(\tn,\tn).
\end{align}

\paragraph{Notación.}
En lo que sigue, se utilizará la siguiente notación (derivada discreta
de $\ynn$):
\begin{equation}
  \label{eq:derivada-discreta}
  \ddt\ynn = \frac{\ynn-\yn}{h}.
\end{equation}
La ecuación~(\ref{eq:euler.taylor.1}) significa que 
$$\ddt\ynn\approx \sol(\tnn)$$
y usando esta notación, el método de Euler se puede escribir como
\begin{equation*}
  \ddt\ynn = f(\tn,\yn).
\end{equation*}

Utilizando distintas aproximaciones de $y'$ se podrían haber expuesto
ahora algunas variantes del método de Euler, pero éstas serán
introducidas a través de fórmulas de integración.

\subsubsection*{Integración numérica}
La solución exacta de~(\ref{eq:pvi}) puede escribirse de la siguiente
forma (formulación integral de la solución de~(\ref{eq:pvi})):
\begin{equation*}
  \sol(t) = \sol(\ta) + \int_\ta^t f(s,\sol(s))\, ds.
\end{equation*}
Tomando $a=\tn$, $t=\tnn$:
\begin{equation*}
  \sol(\tnn) = \sol(\tn) + \int_\tn^\tnn f(s,\sol(s))\, ds.
\end{equation*}
Para obtener el método de Euler implícito aproximamos la última
integral mediante la siguiente fórmula de cuadratura (regla
rectangular izquierda):
\begin{equation*}
  \int_a^b g(s)\,ds \approx hg(a), \quad \text{ con $h=b-a$}.
\end{equation*}
Aplicándola en el intervalo $[\tn,\tnn]$ para la formulación integral
anterior,
\begin{equation*}
  \ynn =  \yn + h f(\tn,\yn),
\end{equation*}
con $\yn\approx\sol(\tn)$, $\ynn\approx\sol(\tnn)$.

\subsubsection*{Algunas variantes del método de Euler.}

Utilizando otras fórmulas de cuadratura, se obtienen métodos numéricos
distintos al de Euler explícito. Por ejemplo:
\begin{enumerate}
\item Aproximando $\int_\tn^\tnn f(s,\sol(s))\, ds$ por la regla
  rectangular derecha,
  \begin{equation*}
    \int_a^b g(s)\,ds \approx hg(b)
  \end{equation*}
  se obtiene el \textit{Método de Euler implícito} (implícito debido a
  que $\ynn$ no puede calcularse explícitamente, pues aparece en el
  segundo miembro)
  \begin{equation}
    \label{eq:euler-implicito}
    \tag{EI}
    \left\{
    \begin{aligned}
      &y_0=\ycero,\\ &\ynn = \yn + h f(\tn,\ynn).
    \end{aligned}
    \right.
  \end{equation}
\item Aproximando $\int_\tn^\tnn f(s,\sol(s))\, ds$ por la regla del
  punto medio (que tiene orden mayor que las reglas rectangular
  derecha e izquierda):
  \begin{equation*}
    \ynn = \yn + h \; f(\tt_{n+1/2},\sol(\tt_{n+1/2})).
  \end{equation*}
  \begin{enumerate}
  \item Si aproximamos seguidamente $\sol(\tt_{n+1/2})$ por
    $\frac12\big(\sol(\tn)+\sol(\tnn)\big)$, se tiene el siguiente
    método implícito, conocido como método de \textit{Crank-Nicolson}
    (primera versión):
    \begin{equation}
    \label{eq:crank-nicolson-1}
      \tag{CN$_1$}
      \left\{
        \begin{aligned}
          &y_0=\ycero,\\ 
          &\ynn = \yn + h \; f\big(\tt_{n+1/2},\; \frac{\yn+\ynn}{2}\big).
        \end{aligned}
      \right.
    \end{equation}
  \item  Si aproximamos $\sol(\tt_{n+1/2})$ por
    $\sol(\tn)+\frac{h}{2}f(\tn,\sol(\tn))$ se llega al método explícito
    conocido como de \textit{Euler--Cauchy} o \textit{Euler modificado}:
    \begin{equation}
      \label{eq:euler-cauchy}
      \tag{EC}
      \left\{
        \begin{aligned}
          &y_0=\ycero,\\ 
          &\ynn = \yn + h \; f\big(\tt_{n+1/2},\;
          \yn+\frac{h}{2}f(\tn,\yn) \big).
        \end{aligned}
      \right.
    \end{equation}
  \end{enumerate}
\item Si aproximamos $\int_\tn^\tnn f(s,\sol(s))\, ds$ por la regla
  del trapecio se llega al siguiente método (segunda variante del
  método de Crank-Nicolson):
  \begin{equation}
    \label{eq:crank-nicolson-1}
    \tag{CN$_2$}
    \left\{
      \begin{aligned}
        &y_0=\ycero,\\ 
        &\ynn = \yn + \frac h2 \; \big\{f(\tn,\;\sol(\tn))+f(\tnn,\;\sol(\tnn))\big\}.
      \end{aligned}
      \right.
    \end{equation}
    Si además aproximamos $\sol(\tnn)$ por
    $\sol(\tn)+hf(\tn,\sol(\tn))$ se llega al método explícito
    conocido como de \textit{Euler mejorado} (o \textit{método de Heunn}):
    \begin{equation}
      \label{eq:euler-mejorado}
      \tag{EM}
      \left\{
        \begin{aligned}
          &y_0=\ycero,\\
          &\ynn = \yn + h \; f\big(\tnn,\;
          \yn+h f(\tn,\yn) \big).
        \end{aligned}
      \right.
    \end{equation}
\end{enumerate}
Estas variantes del método de Euler se pueden escribir en una notación
algo más sencilla (y más cercana a la ecuación diferencial original),
utilizando la derivada discreta definida
en~\eqref{eq:derivada-discreta}. Por ejemplo, el método de Euler
implícito~\eqref{eq:euler-implicito} se sintetiza en:
\begin{equation*}
  y_0=\ycero,\quad \ddt\ynn = f(\tnn,\ynn).
\end{equation*}


\section{Error y convergencia en el método de Euler}
\label{sec:convergencia-euler}


\section{Error y convergencia en métodos generales de un paso}

Por simplicidad, enunciaremos  el resto de los resultados para
funciones globalmente \lipschitz, aunque todos ellos son válidos para
funciones \locLipschitz (en esquemas acotados).


\label{sec:metodos-de-taylor}
Todos los métodos explícitos que hemos enunciado hasta el momento
(Euler~(\ref{eq:metodo-euler}), Euler--Cauchy~(\ref{eq:euler-cauchy}),
Euler mejorado~(\ref{eq:euler-mejorado})) se pueden expresar de la
siguiente forma:
\begin{equation}
  \label{eq:pb-general-1paso} 
  \left\{
  \begin{aligned}
    \text{Dado}\quad &y_0 = \ycero,\\
    \text{hallar}\quad &\ddt\ynn = \Phi(\tn,\yn, h), \quad n=0,\dots,
    N-1,
  \end{aligned}
  \right.
\end{equation}
donde $\Phi:[\ta,\tb]\times \Rset \times [0,h^*] \to \Rset$ es una
función continua dada (que depende de $f$), donde $h^*>0$. Los
conceptos de consistencia, estabilidad y convergencia estudiados en la
sección anterior se pueden generalizar a problemas generales de un
paso, del tipo~(\ref{eq:pb-general-1paso}).

\begin{definition}
  Se llama error de consistencia (en la etapa $t_n$) del problema
  general de un paso~(\ref{eq:pb-general-1paso}) a:
  $${\cal E}_n=\ddt y(\tnn) - \Phi(\tn,y(\tn),h).$$
  El método es consistente si
  $$
  \lim_{h\to 0} ||{\cal E}||_\infty  = 0, \quad \text{donde } {\cal
    E}=({\cal E}_0,...,{\cal E}_N).
  $$
\end{definition}

\newcommand{\Dtotal}[2]{D_{#1}#2} Para enunciar el siguiente teorema
de convergencia, denotamos $D_0f = f$ y, para cada $n\in\Nset$,
$$
\Dtotal n f(x,y) = \frac {\partial^n f}{\partial t^n}(x,y) + f(x,y)
\frac {\partial^n f}{\partial y^n} (x,y).
$$
Recordemos el siguiente resultado de teoría de ecuaciones en derivadas
parciales:
\begin{quotation}
  \emph Si $f\in C^n([\ta,\tb]\times\Rset)$, entonces la solución
  maximal de~(\ref{eq:pvi}) verifica $y\in
  C^{n+1}([\ta,\tb]\times\Rset)$ y además $$y^{n+1}(t)=\Dtotal n f(t,
  y(t))ºº$$.
\end{quotation}

\begin{theorem}[Consistencia]~
  \label{thm:consitencia-pb-general-1paso}
  \begin{enumerate}
  \item Si $f\in C^1([\ta,\tb]\times\Rset)$,
    entonces~(\ref{eq:pb-general-1paso}) es consistente si y solo si 
    \begin{equation*}
      \Phi(t,y,0) = f(t,y)\quad \forall y\in[\ta,\tb]\times\Rset.
    \end{equation*}
  \item Más aún, si $f\in C^p([\ta,\tb]\times\Rset)$ y las derivadas
    parciales con respecto a $h$ existen y son continuas hasta orden
    $p$, entonces
    $$ ||{\cal E}||_\infty<C h^p \quad \text{para algún $C>0$}$$
    si y sólo si:
    \begin{align*}
      \Phi(t,y,0) &= f(x,y), \\
      \frac{\partial\Phi}{\partial h}(t,y,0) &=
      \frac{1}{2}\Dtotal1 f(t,y),
      \\
      \frac{\partial^2\Phi}{\partial h^2}(t,y,0) &=
      \frac{1}{2}\Dtotal2 f(t,y),
      \\
      &\vdots
      \\
      \frac{\partial^{p-1}\Phi}{\partial h^{p-1}}(t,y,0) &=
      \frac{1}{p} \Dtotal{p-1} f(t,y).
    \end{align*}
  \end{enumerate}
\end{theorem}

\begin{proof}
  Véase, por ejemplo la referencia bibliográfica
  [Crouzeix-Mignot].
\end{proof}

\begin{example}~
  \begin{enumerate}
  \item 
    El método de Euler es consistente, con  $ ||{\cal E}||_\infty<C h $
  \item El método de Euler--Cauchy es consitente, con $ ||{\cal
      E}||_\infty<C h^2 $
  \end{enumerate}
\end{example}

Consideremos el siguiente esquema perturbado:

\begin{equation}
  \label{eq:pb-perturbado-general-1paso} 
  \left\{
  \begin{aligned}
    \text{Dado}\quad &z_0 = \ycero+\mu_0,\\
    \text{hallar}\quad &\ddt z_{n+1} = \Phi(\tn,z_n, h) + \delta_n, \quad
    n=0,\dots, N-1,
  \end{aligned}
  \right.
\end{equation}

Como en la sección anterior, decimos que el esquema~(\ref{eq:pb-general-1paso})
es estable si para todo $\epsilon>0$ es posible conseguir
$$
||\yn - z_n||_\infty < \epsilon
$$
tomando $|\mu_0|<\delta$ y $||\delta_n||_\infty<\delta$.

\begin{theorem}
  Si $\Phi$ es globalmente \lipschitz,
  entonces~(\ref{eq:pb-general-1paso}) es estable. En concreto:
  $$
  ||\yn - z_n||_\infty < C_1|y_0-z_0| + C_2 ||\delta_n||_\infty,
  $$
  donde $C_1$ y $C_2$ están definidas como en el teorema de
  estabilidad de la sección anterior.
\end{theorem}
\begin{proof}
  La demostración es similar a la sección anterior: se trata de una
  consecuencia directa del lema de Gronwall discreto, junto al hecho
  de que $\Phi$ sea \lipschitz.<<
\end{proof}
A partir de lo anterior, podemos conseguir la convergencia de los
métodos generales de un paso. En concreto, si definimos el error de
discretización como en la sección anterior, podemos demostrar
fácilmente el siguiente teorema de Convergencia:

\begin{theorem}[Teorema de Lax]
  Si el método general de un paso~(\ref{eq:pb-general-1paso}) es
  consistente y estable, entonces es convergente.
\end{theorem}

\begin{proof}
  Basta aplicar el Teorema de estabilidad a las sucesiones $\yn$
  resultantes del método~(\ref{eq:pb-general-1paso}) y $\z_n=y(\tn)$,
  teniendo en cuenta que en este caso $\delta_n={\cal E}_n$, el error
  de consistencia, que tiende a cero por ser el método convergente.
\end{proof}

\section{Métodos de Taylor. Métodos de Runge-Kutta}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../apuntes-MNII.tex"
%%% End: 